# Query Processing: Query Execution

[toc]

## Physical Operators used in Physical Query Plans

- ==physical query operations== the programs (algorithms) used to execute a query
- ==physical query plan== a sequence of **physical query operations** that accomplishes the execution of a query
- many of the **physical query operations** have multiple implementations
  - some implementations of the the operator are very efficient but require a large amount of memory 
  - while other implementations are less efficient but require smaller amount of memory
- amount of buffers will determine which implementation that we can use to process the query 

## How to estimate costs

- if everything fits in memory
  - standard computational complexity
- if not
  - assume fixed memory available for buffering pages 
  - count I/O operations
  - real systems combine this with CPU estimates

### Cost and constraint of a Physical Query Plan

- the **cost of a physical query plan** *is the number of disk blocks that are accessed by the execution of the* **physical query plan**
- query optimization: find the least cost (physical) query plan such that total memory used by operators $\le$ total available memory buffers

### Assumption in calculating the cost of an operator

- assumption in computing the cost of an operator
  - the output of the operator is left in memory 
    - i.e. the cost of an operation does not include the disk I/O's to write result (to disk)
  - unless the execution plan needs to write the result to disk (to save memory space)

## Processing Model

- a DBMS's ==processing model== defines how the system executes a query plan
  - it specifies things like the direction in which the query plan is read (top-to-bottom / bottom-up) as well as what kind of data is passed between operators along the way
- there are different models of processing models that have various trade-offs for different workloads
  1. **iterator model** (a.k.a. volcano or pipeline model)
  2. **materialization model**
  3. **vectorized / batch model**

### Iterator Model

- this is the most common processing model and is used by almost every (row-based) DBMS
- allows for pipelining where DBMS can process a tuple through many operators as possible before having to retrieve the next tuple
  - series of tasks performed for a given tuple in a query plan is called a ==pipeline==
- every query plan implements the `next` function 
  - on each call to `next`, the operator returns either a single tuple or a `NULL` marker if no more
  - the operator  implements a loop that calls `next` on its children to retrieve their tuples and then process them

### Materialization Model

- this is a specialization of the *iterator model* where each operator processes its input all at once then emits its output all at once
  - instead of having a `next` function that returns a single tuple, each operator returns all of its tuples every time its reached
- this is better for [OLTP](3.5-Storage-Models.md) workloads
  - not good for **OLAP** queries with large intermediate results because the DBMS will have to spill those results to disk between operators

### Vectorization Model

- like *iterator model*, where each operator has a `next` function
- but each operator emits a *batch* (i.e. vector) instead of single tuple 
- the size of the batch can vary based on hardware / query properties
- ideal for **OLAP** that have to scan large number of tuples 

---

## Clustered and unclustered files/relations/indexes

- ==clustered file== file that stores record of one relation
- ==unclustered file== a file that stores records of multiple relations
- ==clustered index== index that allows tuples to be read in an order that corresponds to physical order

---

## Categories of the query processing algorithms

### One-pass algorithms

- read input relations just once
- use the lowest disk I/O operations 
- but also have the highest memory space requirements 
  - store 1 relation in memory 

### 2-pass algorithms

- read input relations 2 times
  - first time the operation performs a preparation step (e.g. sort) and write result to disk
  - second time the prepared result is read and the actual operation is done
- use large number of disk I/O operations
- lower memory space requirements
  - do not store entire relation in memory 
  - only a portion of relation is read

### Multi-pass algorithms

- read input relations more than 2 times
- highest disk I/O's 
- lowest memory space requirements 

### General guideline for picking an algorithm

- if you have sufficient memory, do one-pass
- otherwise check if you have enough for 2-pass
- otherwise, multi-pass

---

## Disk-Oriented DBMS

- in disk-oriented DBMS, we can't assume the query result fits in memory 

### Sorting

- traditional sort algorithms require file must fit in memory 
- ==2-pass multiway merge sort== TPMMS algorithm can be used to sort files larger than memory 

#### The TPMMS algorithm

- suppose
  -  $M$ buffers available for sorting file data
  - 1 buffer can hold 1 data block
- pass 1
  - divide the input file to $M$ blocks 
  - sort each chunk using $M$ buffers
  - write sorted chunks to disk
- pass 2
  - divide $M$ buffers into
    - $M-1$ input buffers (1 buffer to read sorted chunk)
    - 1 output buffer (to write the total sorted output)
  - because we only have $M-1$ input buffers to read the $K$ sorted chunks, we have the constraint that
    - number of sorted chunks $K \le M-1$
  - how to use 1 output buffer to merge sort the $K$ sorted chunks
    - find record with smallest sort key among $K$ chunks
    - move the record with smallest sort key to output buffer
      - if output buffer is full, write `empty` to output buffer
    - if some input buffer is empty
      - read the next sorted block from sorted chunk if there is more data
      - if no more data in chunk then ignore chunk in merge operation 
    - repeat until all chunks processed